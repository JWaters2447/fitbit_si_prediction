{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea81fce8-9e7e-43e7-b012-74b5caeba3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle\n",
    "\n",
    "DATA_DIR = \"../data/cleaned\"\n",
    "DL_DIR = \"../data/deep_learning\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d621ace7-2939-4a79-b6ea-f7a41bf6cb2f",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2fca905-f48c-41eb-a481-3866ca2f5cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_data = pd.read_csv(f\"{DATA_DIR}/combined_data_cleaned.tsv\", sep=\"\\t\").drop(columns = \"SI_max\")\n",
    "\n",
    "# Columns that include 'minute' or 'time in bed' or are named 'age'\n",
    "cols_to_float = [col for col in comb_data.columns \n",
    "                 if ('minute' in col.lower()) or ('time in bed' in col.lower()) or (col.lower() == 'age') or (col == \"TimeInBed\") ]\n",
    "\n",
    "# Convert to float64\n",
    "comb_data[cols_to_float] = comb_data[cols_to_float].astype('float64')\n",
    "\n",
    "comb_data[\"is_SI\"] = np.where(comb_data[\"SI_mean\"] > 1, 1, 0)\n",
    "# comb_data[\"SI_level\"] = np.select([\n",
    "#     comb_data[\"SI_mean\"] == 1,\n",
    "#     comb_data[\"SI_mean\"] < 4,\n",
    "#     comb_data[\"SI_mean\"] >= 4], [0, 1, 2], default=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44444cb-267c-4b31-9537-96f08b748299",
   "metadata": {},
   "source": [
    "### Calculate sample weights for SI_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "823aa78c-fa64-4b2c-ab64-6bb3362374d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_inverse_kde_weights(df, target_col='SI_mean', id_col='PatientID', weight_col_name='si_kde_weight', normalize=True):\n",
    "    \"\"\"\n",
    "    Computes inverse KDE-based importance weights for a target variable using unique samples.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        target_col (str): Name of the target column (e.g., 'SI_mean').\n",
    "        id_col (str): Identifier column (e.g., 'PatientID').\n",
    "        weight_col_name (str): Name for the output weight column.\n",
    "        normalize (bool): Whether to normalize weights to have mean 1.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Weights indexed by PatientID.\n",
    "    \"\"\"\n",
    "    # Step 1: Get unique (PatientID, SI_mean) pairs\n",
    "    unique_df = df[[id_col, target_col]].drop_duplicates()\n",
    "\n",
    "    # Step 2: KDE on unique SI_mean values\n",
    "    si_values = unique_df[target_col].values\n",
    "    kde = gaussian_kde(si_values)\n",
    "    density = kde(si_values)\n",
    "\n",
    "    # Step 3: Invert the density\n",
    "    weights = 1 / (density)\n",
    "\n",
    "    # Step 4: Normalize (optional)\n",
    "    if normalize:\n",
    "        weights = weights / np.mean(weights)\n",
    "\n",
    "    # Step 5: Assign back to PatientID\n",
    "    weight_series = pd.Series(weights, index=unique_df[id_col].values)\n",
    "    \n",
    "    # Map back to full DataFrame\n",
    "    df[weight_col_name] = df[id_col].map(weight_series)\n",
    "    \n",
    "    return df\n",
    "\n",
    "comb_data = compute_inverse_kde_weights(comb_data, target_col=\"SI_mean\", id_col=\"PatientID\", weight_col_name=\"si_kde_weight\", normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e6da0c-1ed4-4188-932d-056a4fc32ede",
   "metadata": {},
   "source": [
    "### Normalize floating point variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4240e81-79c0-4112-a050-ef3c25538731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yeo_johnson_normalize(dfo):\n",
    "    \"\"\"\n",
    "    Applies Yeo-Johnson normalization to float64 columns in the DataFrame,\n",
    "    excluding the 'SI_mean' outcome variable.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        return_transformer (bool): If True, also returns the fitted transformer\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Transformed DataFrame\n",
    "        (optional) sklearn PowerTransformer object\n",
    "    \"\"\"\n",
    "    df = dfo.copy()\n",
    "    \n",
    "    # All float64 columns\n",
    "    float_cols = df.select_dtypes(include=['float64']).columns\n",
    "    \n",
    "    # Exclude the outcome variable\n",
    "    cols_to_transform = [col for col in float_cols if (col != 'SI_mean') and (col != \"si_kde_weight\")]\n",
    "    \n",
    "    # Initialize and apply transformer\n",
    "    pt = PowerTransformer(method='yeo-johnson')\n",
    "    df[cols_to_transform] = pt.fit_transform(df[cols_to_transform])\n",
    "    \n",
    "    return df\n",
    "\n",
    "comb_data_t = yeo_johnson_normalize(comb_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f5958c-c85e-4c2e-be1f-1240d64cd905",
   "metadata": {},
   "source": [
    "### Get Fitbit only data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "719a4c19-dc70-4825-8387-6b92fe26d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    \"PatientID\",\n",
    "    \"BodyBmi\",\n",
    "    \"BodyFat\",\n",
    "    \"BodyWeight\",\n",
    "    \"CaloriesBMR\",\n",
    "    \"FoodCaloriesIn\",\n",
    "    \"HeartRateIntradayCount\",\n",
    "    \"HeartRateZoneOutOfRangeCaloriesOut\",\n",
    "    \"HeartRateZoneOutOfRangeMax\",\n",
    "    \"HeartRateZoneOutOfRangeMinutes\",\n",
    "    \"HeartRateZoneFatBurnCaloriesOut\",\n",
    "    \"HeartRateZoneFatBurnMax\",\n",
    "    \"HeartRateZoneFatBurnMinutes\",\n",
    "    \"HeartRateZoneCardioCaloriesOut\",\n",
    "    \"HeartRateZoneCardioMax\",\n",
    "    \"HeartRateZoneCardioMinutes\",\n",
    "    \"HeartRateZonePeakCaloriesOut\",\n",
    "    \"HeartRateZonePeakMinutes\",\n",
    "    \"TrackerActivityCalories\",\n",
    "    \"TrackerCalories\",\n",
    "    \"TrackerDistance\",\n",
    "    \"TrackerElevation\",\n",
    "    \"TrackerMinutesFairlyActive\",\n",
    "    \"TrackerMinutesLightlyActive\",\n",
    "    \"TrackerMinutesSedentary\",\n",
    "    \"TrackerMinutesVeryActive\",\n",
    "    \"TrackerSteps\",\n",
    "    \"Water\",\n",
    "    \"skipped\",\n",
    "    \"Efficiency\",\n",
    "    \"SleepLevelDeep\",\n",
    "    \"SleepLevelLight\",\n",
    "    \"SleepLevelRem\",\n",
    "    \"SleepLevelWake\",\n",
    "    \"MinutesAfterWakeup\",\n",
    "    \"MinutesAsleep\",\n",
    "    \"MinutesAwake\",\n",
    "    \"MinutesToFallAsleep\",\n",
    "    \"TimeInBed\",\n",
    "    \"times_slept\",\n",
    "    \"SI_mean\",\n",
    "    \"timepoints\",\n",
    "    \"si_kde_weight\",\n",
    "    \"is_SI\",\n",
    "    \n",
    "]\n",
    "\n",
    "# Create the new DataFrame\n",
    "fitbit_data = comb_data[columns_to_keep].copy()\n",
    "fitbit_data_t = comb_data_t[columns_to_keep].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a368a350-47e4-4249-84ef-6adf7b3cc5dd",
   "metadata": {},
   "source": [
    "### Apply one hot encoding to categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe003711-28d4-4a3b-8c92-99c5d21de5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oh(dfo):\n",
    "    '''\n",
    "    Function to get one-hot encoding for survey data\n",
    "    '''\n",
    "    df = dfo.copy().iloc[:, 1:]\n",
    "    \n",
    "    # Select character columns and generate 1 hot encoidng)\n",
    "    object_cols = df.select_dtypes(include='object').columns\n",
    "    df_encoded = pd.get_dummies(df, columns=object_cols, dtype=int)\n",
    "    df = pd.concat([dfo[[\"PatientID\"]], df_encoded], axis=1)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "\n",
    "\n",
    "comb_data_t_oh = get_oh(comb_data_t)\n",
    "# fitbit_data_t_oh = get_oh(fitbit_data_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799a47e8-1269-491c-9a4a-24e481c267c2",
   "metadata": {},
   "source": [
    "### Apply mask for unbalanced time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8936bbb4-7d68-407b-8050-83595fce3355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(dfo, subject_var, mask_var):\n",
    "    '''\n",
    "    Function to apply mask to handle unbalanced timepoints\n",
    "    dfo: dataframe to process.\n",
    "    subject_var: subject identifier column.\n",
    "    mask_var: the column which the mask is based on.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df = dfo.copy()\n",
    "    \n",
    "    # Get number of rows for the matrix (assuming timepoints values represent row indices)\n",
    "    nrow = int(df[mask_var].max())\n",
    "    # Number of columns: drop subject_var and mask_var\n",
    "    ncol = df.shape[1] - 2\n",
    "    \n",
    "    dfg = df.groupby(subject_var)\n",
    "    df_list = []\n",
    "    \n",
    "    for sv in df[subject_var].unique():\n",
    "        # Drop subject_var column (e.g., \"PatientID\")\n",
    "        df1 = dfg.get_group(sv).drop(columns=subject_var)\n",
    "        # Adjust timepoints by subtracting 1 to use as indices (if needed)\n",
    "        tps = (df1[mask_var] - 1).tolist()\n",
    "        # Drop the timepoints column now that we've stored it\n",
    "        df1 = df1.drop(columns=mask_var)\n",
    "        \n",
    "        # Create an empty matrix of shape (nrow, ncol)\n",
    "        zero_matrix = np.zeros((nrow, ncol))\n",
    "        # Fill in the matrix at the rows given by tps\n",
    "        zero_matrix[tps, :] = df1.values\n",
    "        \n",
    "        # Create a DataFrame with the matrix using the correct column names\n",
    "        df2 = pd.DataFrame(zero_matrix, columns=df1.columns)\n",
    "        \n",
    "        # Add an indicator for masked rows: here, we mark rows that are all -1.\n",
    "        # (Adjust this condition if needed; currently it marks a row as 1 if all values are -1.)\n",
    "        df2[\"mask_time\"] = np.where((df2 == -1).all(axis=1), 1, 0)\n",
    "        \n",
    "        # Insert timepoints column at the front (using the number of rows in df2)\n",
    "        df2.insert(0, \"timepoints\", np.arange(df2.shape[0]))\n",
    "        # Insert PatientID column at the very front\n",
    "        df2.insert(0, subject_var, sv)\n",
    "        \n",
    "        df_list.append(df2)\n",
    "    \n",
    "    result_df = pd.concat(df_list, axis=0)\n",
    "    return result_df\n",
    "\n",
    "# Example usage:\n",
    "comb_data_t_oh_mask = get_mask(comb_data_t_oh, \"PatientID\", \"timepoints\")\n",
    "fitbit_t_oh_mask = get_mask(fitbit_data_t, \"PatientID\", \"timepoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7857db7-3198-4442-867c-308364c862d7",
   "metadata": {},
   "source": [
    "### Split data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e58cda2a-463f-4432-85cf-9707d3d95522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_split(df, test_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the data into train and test sets for regression by:\n",
    "      1. Isolating PatientID and SI_mean from the long-form DataFrame.\n",
    "      2. Dropping duplicate PatientID records.\n",
    "      3. Creating SI_mean bins by rounding SI_mean.\n",
    "      4. Performing a stratified train-test split based on these bins.\n",
    "      5. Returning train and test DataFrames that contain all records for the selected PatientIDs.\n",
    "      \n",
    "    Note: The SI_mean_bin column is used only for splitting and is not added back to the final DataFrames.\n",
    "    \"\"\"\n",
    "    # Isolate patient-level data: only PatientID and SI_mean.\n",
    "    patient_df = df[['PatientID', 'SI_mean']].drop_duplicates().copy()\n",
    "    # Create bins by rounding SI_mean.\n",
    "    patient_df['SI_mean_bin'] = patient_df['SI_mean'].round().astype(int)\n",
    "    \n",
    "    # Perform stratified split based on SI_mean_bin.\n",
    "    train_patients, test_patients = train_test_split(\n",
    "        patient_df, test_size=test_size, random_state=random_state, stratify=patient_df['SI_mean_bin']\n",
    "    )\n",
    "    \n",
    "    # Get lists of PatientIDs.\n",
    "    train_ids = train_patients['PatientID'].tolist()\n",
    "    test_ids = test_patients['PatientID'].tolist()\n",
    "    \n",
    "    # Filter the original DataFrame to keep all records for these PatientIDs.\n",
    "    train_df = df[df['PatientID'].isin(train_ids)].copy()\n",
    "    test_df = df[df['PatientID'].isin(test_ids)].copy()\n",
    "    \n",
    "    return {'train': train_df, 'test': test_df}\n",
    "\n",
    "\n",
    "def class_split(df, test_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the data into train and test sets for classification by:\n",
    "      1. Isolating PatientID and is_SI from the long-form DataFrame.\n",
    "      2. Dropping duplicate PatientID records.\n",
    "      3. Performing a stratified split using the is_SI values.\n",
    "      4. Returning train and test DataFrames that contain all records for the selected PatientIDs.\n",
    "    \"\"\"\n",
    "    patient_df = df[['PatientID', 'is_SI']].drop_duplicates().copy()\n",
    "    # For classification, is_SI is binary so we use it directly.\n",
    "    train_patients, test_patients = train_test_split(\n",
    "        patient_df, test_size=test_size, random_state=random_state, stratify=patient_df['is_SI']\n",
    "    )\n",
    "    \n",
    "    train_ids = train_patients['PatientID'].tolist()\n",
    "    test_ids = test_patients['PatientID'].tolist()\n",
    "    \n",
    "    train_df = df[df['PatientID'].isin(train_ids)].copy()\n",
    "    test_df = df[df['PatientID'].isin(test_ids)].copy()\n",
    "    \n",
    "    return {'train': train_df, 'test': test_df}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27a17012-33f2-4d99-a119-a88cea742b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the splits.\n",
    "comb_reg_dict = reg_split(comb_data_t_oh_mask)\n",
    "fitbit_reg_dict = reg_split(fitbit_t_oh_mask)\n",
    "\n",
    "comb_class_dict = class_split(comb_data_t_oh_mask)\n",
    "fitbit_class_dict = class_split(fitbit_t_oh_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca6bebc1-1480-4bd2-968a-1f842ac2d834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the splits for linear modeling\n",
    "comb_reg_dict_lr = reg_split(comb_data)\n",
    "fitbit_reg_dict_lr = reg_split(fitbit_data)\n",
    "\n",
    "comb_class_dict_lr = class_split(comb_data)\n",
    "fitbit_class_dict_lr = class_split(fitbit_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed111d-8ef9-44bb-b866-d7ce78294d7d",
   "metadata": {},
   "source": [
    "### Export data for CNN/LTSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "398b51db-5839-46e1-b090-394e381ec727",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DL_DIR}/comb_reg_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(comb_reg_dict, f)\n",
    "\n",
    "with open(f'{DL_DIR}/fitbit_reg_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(fitbit_reg_dict, f)\n",
    "    \n",
    "with open(f'{DL_DIR}/comb_class_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(comb_class_dict, f)\n",
    "\n",
    "with open(f'{DL_DIR}/fitbit_class_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(fitbit_class_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646fe822-221f-40aa-acfb-49b0eff727a8",
   "metadata": {},
   "source": [
    "### Export for Linear Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ad7e1c8-690b-4917-b14c-6cceb4a91a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cv_tsv(input_dict, subject_id=\"PatientID\", target_var=\"SI_mean\", n_splits=5, output_path=\"fitbit_class_dict.tsv\"):\n",
    "    # Set seeds for reproducibility\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Get the train and test dataframes from the input dictionary\n",
    "    train_df = input_dict[\"train\"].copy()\n",
    "    test_df = input_dict[\"test\"].copy()\n",
    "    \n",
    "    # Create a subject-level dataframe from the training set (unique subjects and their target)\n",
    "    subject_df = train_df[[subject_id, target_var]].drop_duplicates(subset=[subject_id]).copy()\n",
    "    \n",
    "    # For regression, create a new column with the rounded SI_mean values (for stratification)\n",
    "    subject_df[\"SI_mean_levels\"] = subject_df[target_var].round().astype(int)\n",
    "    \n",
    "    # Setup stratified K-fold (stratifying on the rounded target)\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    subjects = subject_df[subject_id].values\n",
    "    strat_labels = subject_df[\"SI_mean_levels\"].values\n",
    "    \n",
    "    # Build a mapping from subject ID to fold number (only for training subjects)\n",
    "    fold_mapping = {}\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(subjects, strat_labels), start=1):\n",
    "        # The test_index in each fold corresponds to subjects assigned to that fold\n",
    "        fold_subjects = subject_df.iloc[test_index][subject_id].values\n",
    "        for sub in fold_subjects:\n",
    "            fold_mapping[sub] = fold\n",
    "    \n",
    "    # For the training set: assign fold numbers and copy the target as \"SI_mean outcome\"\n",
    "    train_df[\"SI_mean fold\"] = train_df[subject_id].map(fold_mapping)\n",
    "    train_df[\"SI_mean outcome\"] = train_df[target_var]\n",
    "    train_df[\"set\"] = \"train\"\n",
    "    \n",
    "    # For the test set: add the two columns with NA values and mark as test\n",
    "    test_df[\"SI_mean fold\"] = np.nan\n",
    "    test_df[\"SI_mean outcome\"] = np.nan\n",
    "    test_df[\"set\"] = \"test\"\n",
    "    \n",
    "    # Concatenate train and test sets\n",
    "    combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "    \n",
    "    # Save the combined DataFrame as a TSV file without the index\n",
    "    combined_df.to_csv(output_path, sep=\"\\t\", index=False)\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac00e59b-d721-4b2c-bf98-96a534b09c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>BodyBmi</th>\n",
       "      <th>BodyFat</th>\n",
       "      <th>BodyWeight</th>\n",
       "      <th>CaloriesBMR</th>\n",
       "      <th>FoodCaloriesIn</th>\n",
       "      <th>HeartRateIntradayCount</th>\n",
       "      <th>HeartRateZoneOutOfRangeCaloriesOut</th>\n",
       "      <th>HeartRateZoneOutOfRangeMax</th>\n",
       "      <th>HeartRateZoneOutOfRangeMinutes</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>sexuality</th>\n",
       "      <th>SI_mean</th>\n",
       "      <th>age</th>\n",
       "      <th>timepoints</th>\n",
       "      <th>is_SI</th>\n",
       "      <th>si_kde_weight</th>\n",
       "      <th>SI_mean fold</th>\n",
       "      <th>SI_mean outcome</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0021BA98-CFA3-4F04-84DD-C642940F5E91</td>\n",
       "      <td>46.882530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.490</td>\n",
       "      <td>1689.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8895.555556</td>\n",
       "      <td>2689.46028</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0021BA98-CFA3-4F04-84DD-C642940F5E91</td>\n",
       "      <td>46.882530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.490</td>\n",
       "      <td>1689.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9092.333333</td>\n",
       "      <td>2037.34584</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0021BA98-CFA3-4F04-84DD-C642940F5E91</td>\n",
       "      <td>46.882530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.490</td>\n",
       "      <td>1702.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9752.333333</td>\n",
       "      <td>2449.85124</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021BA98-CFA3-4F04-84DD-C642940F5E91</td>\n",
       "      <td>46.882530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.490</td>\n",
       "      <td>1708.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10250.111111</td>\n",
       "      <td>2816.24916</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021BA98-CFA3-4F04-84DD-C642940F5E91</td>\n",
       "      <td>46.882530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.490</td>\n",
       "      <td>1708.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10397.777778</td>\n",
       "      <td>2896.66296</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1438.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97897</th>\n",
       "      <td>FFEAB6C6-160F-4CEE-8224-FCC0CCD57479</td>\n",
       "      <td>25.869139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.225</td>\n",
       "      <td>1323.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10940.000000</td>\n",
       "      <td>1556.22012</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97898</th>\n",
       "      <td>FFEAB6C6-160F-4CEE-8224-FCC0CCD57479</td>\n",
       "      <td>25.869139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.225</td>\n",
       "      <td>1323.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9967.000000</td>\n",
       "      <td>1293.44943</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97899</th>\n",
       "      <td>FFEAB6C6-160F-4CEE-8224-FCC0CCD57479</td>\n",
       "      <td>25.869139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.225</td>\n",
       "      <td>1323.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10861.000000</td>\n",
       "      <td>1511.82759</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97900</th>\n",
       "      <td>FFEAB6C6-160F-4CEE-8224-FCC0CCD57479</td>\n",
       "      <td>25.869139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.225</td>\n",
       "      <td>1323.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11328.000000</td>\n",
       "      <td>1477.82089</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97901</th>\n",
       "      <td>FFEAB6C6-160F-4CEE-8224-FCC0CCD57479</td>\n",
       "      <td>25.869139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.225</td>\n",
       "      <td>1323.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11081.000000</td>\n",
       "      <td>1566.97359</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1324.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97902 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  PatientID    BodyBmi  BodyFat  BodyWeight  \\\n",
       "0      0021BA98-CFA3-4F04-84DD-C642940F5E91  46.882530      0.0     112.490   \n",
       "1      0021BA98-CFA3-4F04-84DD-C642940F5E91  46.882530      0.0     112.490   \n",
       "2      0021BA98-CFA3-4F04-84DD-C642940F5E91  46.882530      0.0     112.490   \n",
       "3      0021BA98-CFA3-4F04-84DD-C642940F5E91  46.882530      0.0     112.490   \n",
       "4      0021BA98-CFA3-4F04-84DD-C642940F5E91  46.882530      0.0     112.490   \n",
       "...                                     ...        ...      ...         ...   \n",
       "97897  FFEAB6C6-160F-4CEE-8224-FCC0CCD57479  25.869139      0.0      66.225   \n",
       "97898  FFEAB6C6-160F-4CEE-8224-FCC0CCD57479  25.869139      0.0      66.225   \n",
       "97899  FFEAB6C6-160F-4CEE-8224-FCC0CCD57479  25.869139      0.0      66.225   \n",
       "97900  FFEAB6C6-160F-4CEE-8224-FCC0CCD57479  25.869139      0.0      66.225   \n",
       "97901  FFEAB6C6-160F-4CEE-8224-FCC0CCD57479  25.869139      0.0      66.225   \n",
       "\n",
       "       CaloriesBMR  FoodCaloriesIn  HeartRateIntradayCount  \\\n",
       "0      1689.777778             0.0             8895.555556   \n",
       "1      1689.777778             0.0             9092.333333   \n",
       "2      1702.555556             0.0             9752.333333   \n",
       "3      1708.777778             0.0            10250.111111   \n",
       "4      1708.777778             0.0            10397.777778   \n",
       "...            ...             ...                     ...   \n",
       "97897  1323.000000             0.0            10940.000000   \n",
       "97898  1323.000000             0.0             9967.000000   \n",
       "97899  1323.000000             0.0            10861.000000   \n",
       "97900  1323.000000             0.0            11328.000000   \n",
       "97901  1323.000000             0.0            11081.000000   \n",
       "\n",
       "       HeartRateZoneOutOfRangeCaloriesOut  HeartRateZoneOutOfRangeMax  \\\n",
       "0                              2689.46028                       123.0   \n",
       "1                              2037.34584                       123.0   \n",
       "2                              2449.85124                       123.0   \n",
       "3                              2816.24916                       123.0   \n",
       "4                              2896.66296                       123.0   \n",
       "...                                   ...                         ...   \n",
       "97897                          1556.22012                        92.0   \n",
       "97898                          1293.44943                        92.0   \n",
       "97899                          1511.82759                        92.0   \n",
       "97900                          1477.82089                        92.0   \n",
       "97901                          1566.97359                        92.0   \n",
       "\n",
       "       HeartRateZoneOutOfRangeMinutes  ...  gender     sexuality  SI_mean  \\\n",
       "0                              1435.0  ...  Female  Heterosexual      1.0   \n",
       "1                              1440.0  ...  Female  Heterosexual      1.0   \n",
       "2                              1440.0  ...  Female  Heterosexual      1.0   \n",
       "3                              1439.0  ...  Female  Heterosexual      1.0   \n",
       "4                              1438.0  ...  Female  Heterosexual      1.0   \n",
       "...                               ...  ...     ...           ...      ...   \n",
       "97897                          1327.0  ...  Female  Heterosexual      1.0   \n",
       "97898                          1140.0  ...  Female  Heterosexual      1.0   \n",
       "97899                          1290.0  ...  Female  Heterosexual      1.0   \n",
       "97900                          1283.0  ...  Female  Heterosexual      1.0   \n",
       "97901                          1324.0  ...  Female  Heterosexual      1.0   \n",
       "\n",
       "        age  timepoints  is_SI  si_kde_weight  SI_mean fold  SI_mean outcome  \\\n",
       "0      40.0           1      0       0.099921           1.0              0.0   \n",
       "1      40.0           2      0       0.099921           1.0              0.0   \n",
       "2      40.0           3      0       0.099921           1.0              0.0   \n",
       "3      40.0           4      0       0.099921           1.0              0.0   \n",
       "4      40.0           5      0       0.099921           1.0              0.0   \n",
       "...     ...         ...    ...            ...           ...              ...   \n",
       "97897  36.0          35      0       0.099921           NaN              NaN   \n",
       "97898  36.0          36      0       0.099921           NaN              NaN   \n",
       "97899  36.0          37      0       0.099921           NaN              NaN   \n",
       "97900  36.0          38      0       0.099921           NaN              NaN   \n",
       "97901  36.0          39      0       0.099921           NaN              NaN   \n",
       "\n",
       "         set  \n",
       "0      train  \n",
       "1      train  \n",
       "2      train  \n",
       "3      train  \n",
       "4      train  \n",
       "...      ...  \n",
       "97897   test  \n",
       "97898   test  \n",
       "97899   test  \n",
       "97900   test  \n",
       "97901   test  \n",
       "\n",
       "[97902 rows x 56 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_cv_tsv(fitbit_reg_dict, target_var=\"SI_mean\", output_path=f\"{DL_DIR}/fitbit_reg.tsv\")\n",
    "create_cv_tsv(fitbit_class_dict, target_var=\"is_SI\", output_path=f\"{DL_DIR}/fitbit_class.tsv\")\n",
    "create_cv_tsv(comb_reg_dict, target_var=\"SI_mean\", output_path=f\"{DL_DIR}/comb_reg.tsv\")\n",
    "create_cv_tsv(comb_class_dict, target_var=\"is_SI\", output_path=f\"{DL_DIR}/comb_class.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66623858-7b49-4f62-9b88-e1c8ad925718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL_py_env)",
   "language": "python",
   "name": "dl_py_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

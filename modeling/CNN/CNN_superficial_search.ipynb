{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7cb036-8a29-4188-ba59-d74e8e25b9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda with 5 GPU(s)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold  # (Not used now, but kept if needed elsewhere)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set deterministic behavior for CUDA (set before torch imports)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import optuna\n",
    "import optuna.visualization\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # for multi-GPU\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    return seed\n",
    "\n",
    "# Global device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device} with {torch.cuda.device_count()} GPU(s)\")\n",
    "\n",
    "# Data directory (adjust as needed)\n",
    "DL_DIR = \"../../data/deep_learning\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254431e0-045d-44b4-8e3b-800dcdf86f8f",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6591c5b-a315-4fe9-b8d1-fceee51ae6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the regression split dictionary.\n",
    "with open(f'{DL_DIR}/comb_reg_dict.pkl', 'rb') as f:\n",
    "    comb_reg_dict = pickle.load(f)\n",
    "\n",
    "with open(f'{DL_DIR}/fitbit_reg_dict.pkl', 'rb') as f:\n",
    "    fitbit_reg_dict = pickle.load(f)\n",
    "\n",
    "# Load the classification split dictionary.\n",
    "with open(f'{DL_DIR}/comb_class_dict.pkl', 'rb') as f:\n",
    "    comb_class_dict = pickle.load(f)\n",
    "\n",
    "with open(f'{DL_DIR}/fitbit_class_dict.pkl', 'rb') as f:\n",
    "    fitbit_class_dict = pickle.load(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea5ae9-055d-4ced-b7fb-2b0a36d284e2",
   "metadata": {},
   "source": [
    "### Utility Functions & Dynamic Model Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0ec9f1e-b1b3-42a6-97d1-bbb14aa09cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_output_length(L_in, kernel_size, stride, padding, dilation):\n",
    "    \"\"\"Compute output length after a conv1d layer.\"\"\"\n",
    "    return (L_in + 2 * padding - dilation * (kernel_size - 1) - 1) // stride + 1\n",
    "\n",
    "def pool_output_length(L_in, pool_kernel):\n",
    "    \"\"\"Assuming stride == pool_kernel for pooling.\"\"\"\n",
    "    return L_in // pool_kernel\n",
    "\n",
    "def create_subject_dataset(df, outcome_col=\"SI_mean\"):\n",
    "    \"\"\"\n",
    "    Aggregates records for each subject into a subject-level sample.\n",
    "    Returns a DataFrame with:\n",
    "      - 'X': predictors with shape (n_features, 39)\n",
    "      - the outcome (given by outcome_col)\n",
    "      - sample_weight (if provided)\n",
    "      - a stratification column based on the outcome.\n",
    "    \n",
    "    This function assumes that each subject already has exactly 39 timepoints.\n",
    "    For classification (when outcome_col==\"is_SI\"), if the SI_mean column is absent,\n",
    "    it is not added.\n",
    "    \"\"\"\n",
    "    exclude_cols = [\"PatientID\", \"timepoints\", \"si_kde_weight\", \"SI_mean\", \"is_SI\", \"SI_level\"]\n",
    "    predictor_cols = [col for col in df.columns if col not in (exclude_cols + [outcome_col])]\n",
    "    \n",
    "    subject_data = []\n",
    "    for pid, group in df.groupby(\"PatientID\"):\n",
    "        group_sorted = group.sort_values(\"timepoints\")\n",
    "        # Assume each subject has exactly 39 timepoints.\n",
    "        X = group_sorted[predictor_cols].values.T  # shape: (n_features, 39)\n",
    "        y = group_sorted[outcome_col].iloc[0]\n",
    "        weight = group_sorted[\"si_kde_weight\"].iloc[0] if \"si_kde_weight\" in group.columns else 1.0\n",
    "        record = {\"PatientID\": pid, \"X\": X, outcome_col: y, \"sample_weight\": weight}\n",
    "        if outcome_col == \"is_SI\" and \"SI_mean\" in group_sorted.columns:\n",
    "            record[\"SI_mean\"] = group_sorted[\"SI_mean\"].iloc[0]\n",
    "        subject_data.append(record)\n",
    "    subj_df = pd.DataFrame(subject_data)\n",
    "    subj_df[f\"{outcome_col}_bin\"] = np.round(subj_df[outcome_col]).astype(int)\n",
    "    return subj_df, predictor_cols\n",
    "\n",
    "def get_stratified_cv_splits(df, subject_id=\"PatientID\", target_var=\"SI_mean\", n_splits=5):\n",
    "    \"\"\"\n",
    "    Performs stratified K-fold cross validation at the subject level.\n",
    "    \n",
    "    Parameters:\n",
    "      df : pandas.DataFrame\n",
    "          The original dataframe containing repeated measures.\n",
    "      subject_id : str\n",
    "          The column name for the subject ID (e.g., \"PatientID\").\n",
    "      target_var : str\n",
    "          The target variable; for regression use \"SI_mean\" and for classification use \"is_SI\".\n",
    "      n_splits : int\n",
    "          Number of folds for cross validation.\n",
    "    \n",
    "    Returns:\n",
    "      splits : list of tuples\n",
    "          A list where each element is a tuple (train_df, test_df) corresponding\n",
    "          to one fold. Each dataframe contains all rows (i.e. repeated measures) for the patients in that fold.\n",
    "    \n",
    "    Behavior:\n",
    "      - Isolates unique patient IDs and their target variable by dropping duplicates.\n",
    "      - If target_var is \"SI_mean\", creates a new column \"SI_mean_levels\" (rounded SI_mean).\n",
    "      - Uses the resulting column as the stratification column.\n",
    "      - Performs stratified K-fold CV and then subsets the original dataframe based on the patient IDs.\n",
    "    \"\"\"\n",
    "    # Create a subject-level dataframe (unique patient IDs with their target variable)\n",
    "    subject_df = df[[subject_id, target_var]].drop_duplicates(subset=[subject_id]).copy()\n",
    "    \n",
    "    # For regression: create a new column with the rounded SI_mean values.\n",
    "    if target_var == \"SI_mean\":\n",
    "        subject_df[\"SI_mean_levels\"] = subject_df[target_var].round().astype(int)\n",
    "        strat_col = \"SI_mean_levels\"\n",
    "    else:\n",
    "        strat_col = target_var  # For classification, use the target directly.\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    splits = []\n",
    "    \n",
    "    # Get the subject IDs and stratification labels\n",
    "    subjects = subject_df[subject_id].values\n",
    "    strat_labels = subject_df[strat_col].values\n",
    "    \n",
    "    # For each fold, retrieve patient IDs and then subset the original dataframe.\n",
    "    for train_idx, test_idx in skf.split(subjects, strat_labels):\n",
    "        train_patient_ids = subject_df.iloc[train_idx][subject_id].values\n",
    "        test_patient_ids  = subject_df.iloc[test_idx][subject_id].values\n",
    "        train_split = df[df[subject_id].isin(train_patient_ids)]\n",
    "        test_split  = df[df[subject_id].isin(test_patient_ids)]\n",
    "        splits.append((train_split, test_split))\n",
    "    \n",
    "    return splits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Updated Dynamic Models with Dropout ####\n",
    "class DynamicCNNRegression(nn.Module):\n",
    "    \"\"\"\n",
    "    Builds a dynamic CNN model for regression based on hyperparameters from an Optuna trial.\n",
    "    Dropout is applied after each ReLU activation.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, seq_len, trial):\n",
    "        super(DynamicCNNRegression, self).__init__()\n",
    "        layers = []\n",
    "        # Tune dropout probability as a hyperparameter\n",
    "        dropout_prob = trial.suggest_float(\"dropout_prob\", 0.1, 0.5)\n",
    "        current_channels = input_channels\n",
    "        current_seq_len = seq_len\n",
    "\n",
    "        # ----- Convolutional Layers -----\n",
    "        n_conv = trial.suggest_int(\"n_conv\", 1, 3)\n",
    "        for i in range(n_conv):\n",
    "            n_filters = trial.suggest_int(f\"n_filters_{i}\", 8, 64, step=8)\n",
    "            kernel_size = trial.suggest_int(f\"kernel_size_{i}\", 3, 7, step=2)\n",
    "            dilation = trial.suggest_int(f\"dilation_{i}\", 1, 2)\n",
    "            stride = trial.suggest_int(f\"stride_{i}\", 1, 2)\n",
    "            padding = ((kernel_size - 1) // 2) * dilation\n",
    "            layers.append(nn.Conv1d(in_channels=current_channels,\n",
    "                                    out_channels=n_filters,\n",
    "                                    kernel_size=kernel_size,\n",
    "                                    stride=stride,\n",
    "                                    dilation=dilation,\n",
    "                                    padding=padding))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_prob))\n",
    "            current_seq_len = conv_output_length(current_seq_len, kernel_size, stride, padding, dilation)\n",
    "            \n",
    "            # Optionally add pooling\n",
    "            use_pool = trial.suggest_categorical(f\"use_pool_{i}\", [True, False])\n",
    "            if use_pool:\n",
    "                pool_type = trial.suggest_categorical(f\"pool_type_{i}\", [\"max\", \"avg\"])\n",
    "                suggested_pool_kernel = trial.suggest_int(f\"pool_kernel_{i}\", 2, 4)\n",
    "                pool_kernel = suggested_pool_kernel if current_seq_len >= suggested_pool_kernel else current_seq_len\n",
    "                if pool_kernel > 1:\n",
    "                    if pool_type == \"max\":\n",
    "                        layers.append(nn.MaxPool1d(kernel_size=pool_kernel))\n",
    "                    else:\n",
    "                        layers.append(nn.AvgPool1d(kernel_size=pool_kernel))\n",
    "                    current_seq_len = pool_output_length(current_seq_len, pool_kernel)\n",
    "            current_channels = n_filters\n",
    "\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        \n",
    "        # ----- Fully Connected Layers -----\n",
    "        flattened_dim = current_channels * current_seq_len\n",
    "        n_hidden = trial.suggest_int(\"n_hidden\", 0, 2)\n",
    "        fc_layers = []\n",
    "        in_features = flattened_dim\n",
    "        for j in range(n_hidden):\n",
    "            n_units = trial.suggest_int(f\"n_units_{j}\", 16, 128, step=16)\n",
    "            fc_layers.append(nn.Linear(in_features, n_units))\n",
    "            fc_layers.append(nn.ReLU())\n",
    "            fc_layers.append(nn.Dropout(dropout_prob))\n",
    "            in_features = n_units\n",
    "        fc_layers.append(nn.Linear(in_features, 1))\n",
    "        self.fc = nn.Sequential(*fc_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class DynamicCNNClassification(nn.Module):\n",
    "    \"\"\"\n",
    "    Builds a dynamic CNN model for binary classification based on hyperparameters from an Optuna trial.\n",
    "    Dropout is applied after each ReLU activation.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, seq_len, trial):\n",
    "        super(DynamicCNNClassification, self).__init__()\n",
    "        layers = []\n",
    "        dropout_prob = trial.suggest_float(\"dropout_prob\", 0.1, 0.5)\n",
    "        current_channels = input_channels\n",
    "        current_seq_len = seq_len\n",
    "\n",
    "        # ----- Convolutional Layers -----\n",
    "        n_conv = trial.suggest_int(\"n_conv\", 1, 3)\n",
    "        for i in range(n_conv):\n",
    "            n_filters = trial.suggest_int(f\"n_filters_{i}\", 8, 64, step=8)\n",
    "            kernel_size = trial.suggest_int(f\"kernel_size_{i}\", 3, 7, step=2)\n",
    "            dilation = trial.suggest_int(f\"dilation_{i}\", 1, 2)\n",
    "            stride = trial.suggest_int(f\"stride_{i}\", 1, 2)\n",
    "            padding = ((kernel_size - 1) // 2) * dilation\n",
    "            layers.append(nn.Conv1d(in_channels=current_channels,\n",
    "                                    out_channels=n_filters,\n",
    "                                    kernel_size=kernel_size,\n",
    "                                    stride=stride,\n",
    "                                    dilation=dilation,\n",
    "                                    padding=padding))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_prob))\n",
    "            current_seq_len = conv_output_length(current_seq_len, kernel_size, stride, padding, dilation)\n",
    "            \n",
    "            use_pool = trial.suggest_categorical(f\"use_pool_{i}\", [True, False])\n",
    "            if use_pool:\n",
    "                pool_type = trial.suggest_categorical(f\"pool_type_{i}\", [\"max\", \"avg\"])\n",
    "                suggested_pool_kernel = trial.suggest_int(f\"pool_kernel_{i}\", 2, 4)\n",
    "                pool_kernel = suggested_pool_kernel if current_seq_len >= suggested_pool_kernel else current_seq_len\n",
    "                if pool_kernel > 1:\n",
    "                    if pool_type == \"max\":\n",
    "                        layers.append(nn.MaxPool1d(kernel_size=pool_kernel))\n",
    "                    else:\n",
    "                        layers.append(nn.AvgPool1d(kernel_size=pool_kernel))\n",
    "                    current_seq_len = pool_output_length(current_seq_len, pool_kernel)\n",
    "            current_channels = n_filters\n",
    "\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        \n",
    "        # ----- Fully Connected Layers -----\n",
    "        flattened_dim = current_channels * current_seq_len\n",
    "        n_hidden = trial.suggest_int(\"n_hidden\", 0, 2)\n",
    "        fc_layers = []\n",
    "        in_features = flattened_dim\n",
    "        for j in range(n_hidden):\n",
    "            n_units = trial.suggest_int(f\"n_units_{j}\", 16, 128, step=16)\n",
    "            fc_layers.append(nn.Linear(in_features, n_units))\n",
    "            fc_layers.append(nn.ReLU())\n",
    "            fc_layers.append(nn.Dropout(dropout_prob))\n",
    "            in_features = n_units\n",
    "        fc_layers.append(nn.Linear(in_features, 1))  # final logit for binary classification\n",
    "        self.fc = nn.Sequential(*fc_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0083479-6a47-4b33-9952-dba5eb3f13e2",
   "metadata": {},
   "source": [
    "### Objective Function with 5-Fold Stratified Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ee47511-1800-4449-a212-61936413212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_regression(trial, data_dict, use_sample_weights, model_name):\n",
    "    set_seed(42)\n",
    "    # Process only the training portion from the dictionary.\n",
    "    train_df, _ = create_subject_dataset(data_dict['train'], outcome_col=\"SI_mean\")\n",
    "    X = np.stack(train_df[\"X\"].values, axis=0)  # shape: (n_subjects, n_features, 39)\n",
    "    y = train_df[\"SI_mean\"].values\n",
    "    w = train_df[\"sample_weight\"].values if use_sample_weights else np.ones_like(y, dtype=np.float32)\n",
    "    n_subjects, input_channels, seq_len = X.shape\n",
    "\n",
    "    # Get the stratified CV splits from the helper function.\n",
    "    # Stratification is based on PatientID and the binned SI_mean (SI_mean_bin).\n",
    "    cv_splits = get_stratified_cv_splits(train_df, subject_id=\"PatientID\", target_var=\"SI_mean\", n_splits=5)\n",
    "\n",
    "    # Suggest hyperparameters once per trial.\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2)\n",
    "    use_reg = trial.suggest_categorical(\"use_regularization\", [True, False])\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-3) if use_reg else 0.0\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 16, 64, step=16)\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 5, 10)\n",
    "\n",
    "    rmse_list = []\n",
    "    for cv_train_df, cv_val_df in cv_splits:\n",
    "        X_train_fold = np.stack(cv_train_df[\"X\"].values, axis=0)\n",
    "        y_train_fold = cv_train_df[\"SI_mean\"].values\n",
    "        w_train_fold = cv_train_df[\"sample_weight\"].values if use_sample_weights else np.ones_like(y_train_fold, dtype=np.float32)\n",
    "        X_val_fold   = np.stack(cv_val_df[\"X\"].values, axis=0)\n",
    "        y_val_fold   = cv_val_df[\"SI_mean\"].values\n",
    "\n",
    "        # Build the dynamic CNN regression model with the trialâ€™s architecture choices.\n",
    "        model = DynamicCNNRegression(input_channels, seq_len, trial).to(device)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        loss_fn = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "        train_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.tensor(X_train_fold, dtype=torch.float32),\n",
    "            torch.tensor(y_train_fold, dtype=torch.float32).view(-1, 1),\n",
    "            torch.tensor(w_train_fold, dtype=torch.float32)\n",
    "        )\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "        \n",
    "        model.train()\n",
    "        for ep in range(num_epochs):\n",
    "            for X_batch, y_batch, weight_batch in train_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                weight_batch = weight_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss_per_sample = loss_fn(outputs, y_batch).view(-1)\n",
    "                loss = (loss_per_sample * weight_batch).mean() if use_sample_weights else loss_per_sample.mean()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_val_tensor = torch.tensor(X_val_fold, dtype=torch.float32).to(device)\n",
    "            preds = model(X_val_tensor).cpu().numpy()\n",
    "        fold_rmse = np.sqrt(np.mean((preds - y_val_fold.reshape(-1, 1)) ** 2))\n",
    "        rmse_list.append(fold_rmse)\n",
    "    \n",
    "    mean_rmse = np.mean(rmse_list)\n",
    "    return mean_rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a0ebb1-b342-4387-89b5-27cc7b449cb3",
   "metadata": {},
   "source": [
    "###  Run the Superficial Optuna Search & Save Hyperparameter Importance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c8633d6-3d37-49ac-8cf7-aeeec03096df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_superficial_search_regression(data_dict, use_sample_weights, model_name, n_trials=5):\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    def print_progress(study, trial):\n",
    "        print(f\"{model_name} trial {len(study.trials)}/{n_trials}\\r\", end=\"\", flush=True)\n",
    "    \n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(lambda trial: objective_regression(trial, data_dict, use_sample_weights, model_name),\n",
    "                   n_trials=n_trials, callbacks=[print_progress])\n",
    "    \n",
    "    fig = optuna.visualization.plot_param_importances(study)\n",
    "    plot_filename = f\"search/{model_name}_hyperparam_importance.png\"\n",
    "    fig.write_image(plot_filename)\n",
    "    \n",
    "    rows = []\n",
    "    for t in study.trials:\n",
    "        row = {\"model\": model_name,\n",
    "               \"type\": \"weighted\" if use_sample_weights else \"not weighted\",\n",
    "               \"overall_rmse\": t.value,\n",
    "               \"config\": t.params}\n",
    "        rows.append(row)\n",
    "    result_df = pd.DataFrame(rows)\n",
    "    \n",
    "    best_trial = study.best_trial\n",
    "    optimal_configuration = {\"value\": best_trial.value,\n",
    "                             \"params\": best_trial.params,\n",
    "                             \"user_attrs\": best_trial.user_attrs}\n",
    "    \n",
    "    result_dict = {\"results\": result_df,\n",
    "                   \"optimal_configuration\": optimal_configuration,\n",
    "                   \"importance_plot\": plot_filename}\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbebba5-786c-4e3b-874d-6176a44a7c6e",
   "metadata": {},
   "source": [
    "### Run an Optuna study for a given dataset and weighting configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a29b34e-537b-417e-b880-f4b891285dd4",
   "metadata": {},
   "source": [
    "### Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21c7947f-c8e2-4cc9-8edb-21e6a2fe4ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comb_reg_superficial trial 20/20\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'results':                    model      type  overall_rmse  \\\n",
       " 0   comb_reg_superficial  weighted      1.077803   \n",
       " 1   comb_reg_superficial  weighted      0.805814   \n",
       " 2   comb_reg_superficial  weighted      1.074576   \n",
       " 3   comb_reg_superficial  weighted      1.396296   \n",
       " 4   comb_reg_superficial  weighted      1.354603   \n",
       " 5   comb_reg_superficial  weighted      0.997967   \n",
       " 6   comb_reg_superficial  weighted      1.361521   \n",
       " 7   comb_reg_superficial  weighted      1.525523   \n",
       " 8   comb_reg_superficial  weighted      0.915472   \n",
       " 9   comb_reg_superficial  weighted      1.140880   \n",
       " 10  comb_reg_superficial  weighted      1.038099   \n",
       " 11  comb_reg_superficial  weighted      1.090438   \n",
       " 12  comb_reg_superficial  weighted      1.459692   \n",
       " 13  comb_reg_superficial  weighted      1.303128   \n",
       " 14  comb_reg_superficial  weighted      1.662313   \n",
       " 15  comb_reg_superficial  weighted      1.588079   \n",
       " 16  comb_reg_superficial  weighted      0.997922   \n",
       " 17  comb_reg_superficial  weighted      1.015615   \n",
       " 18  comb_reg_superficial  weighted      0.816976   \n",
       " 19  comb_reg_superficial  weighted      0.944324   \n",
       " \n",
       "                                                config  \n",
       " 0   {'lr': 0.0010047826456241816, 'use_regularizat...  \n",
       " 1   {'lr': 0.0006509986398590246, 'use_regularizat...  \n",
       " 2   {'lr': 0.0009320051121837186, 'use_regularizat...  \n",
       " 3   {'lr': 1.4698971703052386e-05, 'use_regulariza...  \n",
       " 4   {'lr': 0.0028886380772200253, 'use_regularizat...  \n",
       " 5   {'lr': 0.00014691308202659318, 'use_regulariza...  \n",
       " 6   {'lr': 0.002057335927070369, 'use_regularizati...  \n",
       " 7   {'lr': 0.0001507560065330573, 'use_regularizat...  \n",
       " 8   {'lr': 4.8941256928298194e-05, 'use_regulariza...  \n",
       " 9   {'lr': 0.004087530637136374, 'use_regularizati...  \n",
       " 10  {'lr': 0.0004038700708938604, 'use_regularizat...  \n",
       " 11  {'lr': 3.1696351991124456e-05, 'use_regulariza...  \n",
       " 12  {'lr': 5.163368825852682e-05, 'use_regularizat...  \n",
       " 13  {'lr': 0.00010744062577408148, 'use_regulariza...  \n",
       " 14  {'lr': 0.0004045356632892799, 'use_regularizat...  \n",
       " 15  {'lr': 0.008672882393615765, 'use_regularizati...  \n",
       " 16  {'lr': 4.273265272755411e-05, 'use_regularizat...  \n",
       " 17  {'lr': 0.0008312369421719536, 'use_regularizat...  \n",
       " 18  {'lr': 1.356072830445357e-05, 'use_regularizat...  \n",
       " 19  {'lr': 0.0002828418955426019, 'use_regularizat...  ,\n",
       " 'optimal_configuration': {'value': 0.8058141016156984,\n",
       "  'params': {'lr': 0.0006509986398590246,\n",
       "   'use_regularization': False,\n",
       "   'batch_size': 48,\n",
       "   'num_epochs': 7,\n",
       "   'dropout_prob': 0.31940354339116694,\n",
       "   'n_conv': 2,\n",
       "   'n_filters_0': 16,\n",
       "   'kernel_size_0': 5,\n",
       "   'dilation_0': 1,\n",
       "   'stride_0': 2,\n",
       "   'use_pool_0': True,\n",
       "   'pool_type_0': 'max',\n",
       "   'pool_kernel_0': 4,\n",
       "   'n_filters_1': 64,\n",
       "   'kernel_size_1': 3,\n",
       "   'dilation_1': 2,\n",
       "   'stride_1': 2,\n",
       "   'use_pool_1': True,\n",
       "   'pool_type_1': 'max',\n",
       "   'pool_kernel_1': 2,\n",
       "   'n_hidden': 1,\n",
       "   'n_units_0': 96},\n",
       "  'user_attrs': {}},\n",
       " 'importance_plot': 'search/comb_reg_superficial_hyperparam_importance.png'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_superficial_search_regression(comb_reg_dict, use_sample_weights=True, model_name=\"comb_reg_superficial\", n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed39d7da-d990-4906-8355-f9824318e05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitbit_reg_superficial trial 20/20\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'results':                      model      type  overall_rmse  \\\n",
       " 0   fitbit_reg_superficial  weighted      1.157431   \n",
       " 1   fitbit_reg_superficial  weighted      1.291520   \n",
       " 2   fitbit_reg_superficial  weighted      0.725654   \n",
       " 3   fitbit_reg_superficial  weighted      1.578346   \n",
       " 4   fitbit_reg_superficial  weighted      1.322916   \n",
       " 5   fitbit_reg_superficial  weighted      1.486152   \n",
       " 6   fitbit_reg_superficial  weighted      1.365617   \n",
       " 7   fitbit_reg_superficial  weighted      0.671264   \n",
       " 8   fitbit_reg_superficial  weighted      1.366532   \n",
       " 9   fitbit_reg_superficial  weighted      0.641342   \n",
       " 10  fitbit_reg_superficial  weighted      0.809376   \n",
       " 11  fitbit_reg_superficial  weighted      0.677573   \n",
       " 12  fitbit_reg_superficial  weighted      0.806698   \n",
       " 13  fitbit_reg_superficial  weighted      0.990587   \n",
       " 14  fitbit_reg_superficial  weighted      0.953094   \n",
       " 15  fitbit_reg_superficial  weighted      0.996520   \n",
       " 16  fitbit_reg_superficial  weighted      0.718990   \n",
       " 17  fitbit_reg_superficial  weighted      1.350888   \n",
       " 18  fitbit_reg_superficial  weighted      1.591900   \n",
       " 19  fitbit_reg_superficial  weighted      1.221373   \n",
       " \n",
       "                                                config  \n",
       " 0   {'lr': 0.000578669546645847, 'use_regularizati...  \n",
       " 1   {'lr': 1.7379060153734716e-05, 'use_regulariza...  \n",
       " 2   {'lr': 4.2749057761105184e-05, 'use_regulariza...  \n",
       " 3   {'lr': 0.00020109551214351638, 'use_regulariza...  \n",
       " 4   {'lr': 0.002306697822277, 'use_regularization'...  \n",
       " 5   {'lr': 0.00013516160045963965, 'use_regulariza...  \n",
       " 6   {'lr': 0.0007590017384871533, 'use_regularizat...  \n",
       " 7   {'lr': 0.00858407139246924, 'use_regularizatio...  \n",
       " 8   {'lr': 0.00032892307862277215, 'use_regulariza...  \n",
       " 9   {'lr': 0.00010082281420217833, 'use_regulariza...  \n",
       " 10  {'lr': 2.9548344435681222e-05, 'use_regulariza...  \n",
       " 11  {'lr': 0.0037152813586805535, 'use_regularizat...  \n",
       " 12  {'lr': 8.452046066051413e-05, 'use_regularizat...  \n",
       " 13  {'lr': 0.008028199654758657, 'use_regularizati...  \n",
       " 14  {'lr': 0.0015261902920193798, 'use_regularizat...  \n",
       " 15  {'lr': 0.008039119167323052, 'use_regularizati...  \n",
       " 16  {'lr': 6.694365919393949e-05, 'use_regularizat...  \n",
       " 17  {'lr': 1.5000400836694615e-05, 'use_regulariza...  \n",
       " 18  {'lr': 0.00043885532276404855, 'use_regulariza...  \n",
       " 19  {'lr': 0.0010231112566821243, 'use_regularizat...  ,\n",
       " 'optimal_configuration': {'value': 0.6413415637451672,\n",
       "  'params': {'lr': 0.00010082281420217833,\n",
       "   'use_regularization': False,\n",
       "   'batch_size': 64,\n",
       "   'num_epochs': 10,\n",
       "   'dropout_prob': 0.3582404126536324,\n",
       "   'n_conv': 3,\n",
       "   'n_filters_0': 32,\n",
       "   'kernel_size_0': 5,\n",
       "   'dilation_0': 2,\n",
       "   'stride_0': 1,\n",
       "   'use_pool_0': False,\n",
       "   'n_filters_1': 64,\n",
       "   'kernel_size_1': 7,\n",
       "   'dilation_1': 1,\n",
       "   'stride_1': 1,\n",
       "   'use_pool_1': True,\n",
       "   'pool_type_1': 'max',\n",
       "   'pool_kernel_1': 2,\n",
       "   'n_filters_2': 16,\n",
       "   'kernel_size_2': 5,\n",
       "   'dilation_2': 1,\n",
       "   'stride_2': 2,\n",
       "   'use_pool_2': True,\n",
       "   'pool_type_2': 'max',\n",
       "   'pool_kernel_2': 3,\n",
       "   'n_hidden': 2,\n",
       "   'n_units_0': 80,\n",
       "   'n_units_1': 112},\n",
       "  'user_attrs': {}},\n",
       " 'importance_plot': 'search/fitbit_reg_superficial_hyperparam_importance.png'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_superficial_search_regression(fitbit_reg_dict, use_sample_weights=True, model_name=\"fitbit_reg_superficial\", n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfc7af6-5ccd-4984-870b-612e9cabd33e",
   "metadata": {},
   "source": [
    "### Not Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4c8eece-7b41-4694-8663-36ca7c6adfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comb_reg_superficial_nw trial 20/20\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'results':                       model          type  overall_rmse  \\\n",
       " 0   comb_reg_superficial_nw  not weighted      0.652197   \n",
       " 1   comb_reg_superficial_nw  not weighted      0.617605   \n",
       " 2   comb_reg_superficial_nw  not weighted      0.661722   \n",
       " 3   comb_reg_superficial_nw  not weighted      0.649703   \n",
       " 4   comb_reg_superficial_nw  not weighted      0.629274   \n",
       " 5   comb_reg_superficial_nw  not weighted      0.604076   \n",
       " 6   comb_reg_superficial_nw  not weighted      0.598998   \n",
       " 7   comb_reg_superficial_nw  not weighted      0.630121   \n",
       " 8   comb_reg_superficial_nw  not weighted      0.835498   \n",
       " 9   comb_reg_superficial_nw  not weighted      0.827271   \n",
       " 10  comb_reg_superficial_nw  not weighted      0.629864   \n",
       " 11  comb_reg_superficial_nw  not weighted      1.106040   \n",
       " 12  comb_reg_superficial_nw  not weighted      0.601481   \n",
       " 13  comb_reg_superficial_nw  not weighted      0.623442   \n",
       " 14  comb_reg_superficial_nw  not weighted      0.600564   \n",
       " 15  comb_reg_superficial_nw  not weighted      0.628198   \n",
       " 16  comb_reg_superficial_nw  not weighted      0.603106   \n",
       " 17  comb_reg_superficial_nw  not weighted      1.227975   \n",
       " 18  comb_reg_superficial_nw  not weighted      0.626492   \n",
       " 19  comb_reg_superficial_nw  not weighted      0.656652   \n",
       " \n",
       "                                                config  \n",
       " 0   {'lr': 0.004079439045282261, 'use_regularizati...  \n",
       " 1   {'lr': 2.8523949807329864e-05, 'use_regulariza...  \n",
       " 2   {'lr': 0.00027197867421954204, 'use_regulariza...  \n",
       " 3   {'lr': 0.004468823075654059, 'use_regularizati...  \n",
       " 4   {'lr': 0.005467837707487373, 'use_regularizati...  \n",
       " 5   {'lr': 3.9394757299304676e-05, 'use_regulariza...  \n",
       " 6   {'lr': 0.0001765776177521328, 'use_regularizat...  \n",
       " 7   {'lr': 0.00011078236017359808, 'use_regulariza...  \n",
       " 8   {'lr': 3.5270584168162864e-05, 'use_regulariza...  \n",
       " 9   {'lr': 0.0001777753911200818, 'use_regularizat...  \n",
       " 10  {'lr': 0.0009258361888163629, 'use_regularizat...  \n",
       " 11  {'lr': 1.5833230835852222e-05, 'use_regulariza...  \n",
       " 12  {'lr': 7.115887055957011e-05, 'use_regularizat...  \n",
       " 13  {'lr': 0.0006643210180583133, 'use_regularizat...  \n",
       " 14  {'lr': 8.48219948988714e-05, 'use_regularizati...  \n",
       " 15  {'lr': 0.0007340804247472008, 'use_regularizat...  \n",
       " 16  {'lr': 9.900935725975386e-05, 'use_regularizat...  \n",
       " 17  {'lr': 1.0426838798032143e-05, 'use_regulariza...  \n",
       " 18  {'lr': 0.000387171657254495, 'use_regularizati...  \n",
       " 19  {'lr': 0.002072297331769538, 'use_regularizati...  ,\n",
       " 'optimal_configuration': {'value': 0.598998132583919,\n",
       "  'params': {'lr': 0.0001765776177521328,\n",
       "   'use_regularization': False,\n",
       "   'batch_size': 64,\n",
       "   'num_epochs': 6,\n",
       "   'dropout_prob': 0.10841547266313412,\n",
       "   'n_conv': 2,\n",
       "   'n_filters_0': 56,\n",
       "   'kernel_size_0': 7,\n",
       "   'dilation_0': 1,\n",
       "   'stride_0': 1,\n",
       "   'use_pool_0': True,\n",
       "   'pool_type_0': 'avg',\n",
       "   'pool_kernel_0': 4,\n",
       "   'n_filters_1': 16,\n",
       "   'kernel_size_1': 3,\n",
       "   'dilation_1': 1,\n",
       "   'stride_1': 1,\n",
       "   'use_pool_1': True,\n",
       "   'pool_type_1': 'avg',\n",
       "   'pool_kernel_1': 4,\n",
       "   'n_hidden': 1,\n",
       "   'n_units_0': 16},\n",
       "  'user_attrs': {}},\n",
       " 'importance_plot': 'search/comb_reg_superficial_nw_hyperparam_importance.png'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_superficial_search_regression(comb_reg_dict, use_sample_weights=False, model_name=\"comb_reg_superficial_nw\", n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c95f4ab-1d78-4cf0-9d0c-9fd55fb18a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitbit_reg_superficial_nw trial 20/20\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'results':                         model          type  overall_rmse  \\\n",
       " 0   fitbit_reg_superficial_nw  not weighted      0.627845   \n",
       " 1   fitbit_reg_superficial_nw  not weighted      0.652370   \n",
       " 2   fitbit_reg_superficial_nw  not weighted      0.687655   \n",
       " 3   fitbit_reg_superficial_nw  not weighted      0.621692   \n",
       " 4   fitbit_reg_superficial_nw  not weighted      0.612285   \n",
       " 5   fitbit_reg_superficial_nw  not weighted      0.615260   \n",
       " 6   fitbit_reg_superficial_nw  not weighted      0.799828   \n",
       " 7   fitbit_reg_superficial_nw  not weighted      0.652783   \n",
       " 8   fitbit_reg_superficial_nw  not weighted      0.710526   \n",
       " 9   fitbit_reg_superficial_nw  not weighted      0.637370   \n",
       " 10  fitbit_reg_superficial_nw  not weighted      0.620302   \n",
       " 11  fitbit_reg_superficial_nw  not weighted      0.604470   \n",
       " 12  fitbit_reg_superficial_nw  not weighted      0.609234   \n",
       " 13  fitbit_reg_superficial_nw  not weighted      0.617111   \n",
       " 14  fitbit_reg_superficial_nw  not weighted      0.603432   \n",
       " 15  fitbit_reg_superficial_nw  not weighted      0.599244   \n",
       " 16  fitbit_reg_superficial_nw  not weighted      0.602489   \n",
       " 17  fitbit_reg_superficial_nw  not weighted      0.602777   \n",
       " 18  fitbit_reg_superficial_nw  not weighted      0.614814   \n",
       " 19  fitbit_reg_superficial_nw  not weighted      0.766892   \n",
       " \n",
       "                                                config  \n",
       " 0   {'lr': 0.0022816056220443613, 'use_regularizat...  \n",
       " 1   {'lr': 0.0008366491496482589, 'use_regularizat...  \n",
       " 2   {'lr': 3.156160723530171e-05, 'use_regularizat...  \n",
       " 3   {'lr': 0.00013447796307040666, 'use_regulariza...  \n",
       " 4   {'lr': 5.25026296192685e-05, 'use_regularizati...  \n",
       " 5   {'lr': 0.003091424234427365, 'use_regularizati...  \n",
       " 6   {'lr': 0.0005089092636940897, 'use_regularizat...  \n",
       " 7   {'lr': 9.32470217056811e-05, 'use_regularizati...  \n",
       " 8   {'lr': 0.0014207821604666803, 'use_regularizat...  \n",
       " 9   {'lr': 0.008260138507449569, 'use_regularizati...  \n",
       " 10  {'lr': 1.2122982664188581e-05, 'use_regulariza...  \n",
       " 11  {'lr': 0.007786832431195689, 'use_regularizati...  \n",
       " 12  {'lr': 0.00012394348862199102, 'use_regulariza...  \n",
       " 13  {'lr': 0.0001927727884091451, 'use_regularizat...  \n",
       " 14  {'lr': 0.006800119994197248, 'use_regularizati...  \n",
       " 15  {'lr': 0.0072658990241851315, 'use_regularizat...  \n",
       " 16  {'lr': 0.004107209585548919, 'use_regularizati...  \n",
       " 17  {'lr': 0.0032999317389737336, 'use_regularizat...  \n",
       " 18  {'lr': 0.0004017522114684115, 'use_regularizat...  \n",
       " 19  {'lr': 0.0010313643533155714, 'use_regularizat...  ,\n",
       " 'optimal_configuration': {'value': 0.5992439834226684,\n",
       "  'params': {'lr': 0.0072658990241851315,\n",
       "   'use_regularization': False,\n",
       "   'batch_size': 16,\n",
       "   'num_epochs': 9,\n",
       "   'dropout_prob': 0.36319612740976537,\n",
       "   'n_conv': 3,\n",
       "   'n_filters_0': 64,\n",
       "   'kernel_size_0': 7,\n",
       "   'dilation_0': 1,\n",
       "   'stride_0': 1,\n",
       "   'use_pool_0': True,\n",
       "   'pool_type_0': 'avg',\n",
       "   'pool_kernel_0': 3,\n",
       "   'n_filters_1': 24,\n",
       "   'kernel_size_1': 7,\n",
       "   'dilation_1': 2,\n",
       "   'stride_1': 1,\n",
       "   'use_pool_1': True,\n",
       "   'pool_type_1': 'avg',\n",
       "   'pool_kernel_1': 3,\n",
       "   'n_filters_2': 64,\n",
       "   'kernel_size_2': 7,\n",
       "   'dilation_2': 2,\n",
       "   'stride_2': 2,\n",
       "   'use_pool_2': True,\n",
       "   'pool_type_2': 'avg',\n",
       "   'pool_kernel_2': 2,\n",
       "   'n_hidden': 1,\n",
       "   'n_units_0': 64},\n",
       "  'user_attrs': {}},\n",
       " 'importance_plot': 'search/fitbit_reg_superficial_nw_hyperparam_importance.png'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_superficial_search_regression(fitbit_reg_dict, use_sample_weights=False, model_name=\"fitbit_reg_superficial_nw\", n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcfe371-b318-4515-901e-d565a20e061d",
   "metadata": {},
   "source": [
    "### Superficial search for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef7ea051-f4c4-4cad-851e-7025917d945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_classification(trial, data_dict, use_sample_weights, model_name):\n",
    "    set_seed(42)\n",
    "    # Process only the training portion.\n",
    "    train_df, _ = create_subject_dataset(data_dict['train'], outcome_col=\"is_SI\")\n",
    "    X = np.stack(train_df[\"X\"].values, axis=0)\n",
    "    y = train_df[\"is_SI\"].values.astype(np.float32)\n",
    "    w = train_df[\"sample_weight\"].values if use_sample_weights else np.ones_like(y, dtype=np.float32)\n",
    "    n_subjects, input_channels, seq_len = X.shape\n",
    "\n",
    "    # Get stratified CV splits using the helper function.\n",
    "    cv_splits = get_stratified_cv_splits(train_df, subject_id=\"PatientID\", target_var=\"is_SI\", n_splits=5)\n",
    "\n",
    "    # Suggest hyperparameters once per trial.\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2)\n",
    "    use_reg = trial.suggest_categorical(\"use_regularization\", [True, False])\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-3) if use_reg else 0.0\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 16, 64, step=16)\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 5, 10)\n",
    "\n",
    "    acc_list = []\n",
    "    sens_list = []\n",
    "    spec_list = []\n",
    "    for cv_train_df, cv_val_df in cv_splits:\n",
    "        X_train_fold = np.stack(cv_train_df[\"X\"].values, axis=0)\n",
    "        y_train_fold = cv_train_df[\"is_SI\"].values.astype(np.float32)\n",
    "        w_train_fold = cv_train_df[\"sample_weight\"].values if use_sample_weights else np.ones_like(y_train_fold, dtype=np.float32)\n",
    "        X_val_fold = np.stack(cv_val_df[\"X\"].values, axis=0)\n",
    "        y_val_fold = cv_val_df[\"is_SI\"].values.astype(np.float32)\n",
    "\n",
    "        # Build the dynamic CNN classification model with trial's hyperparameters.\n",
    "        model = DynamicCNNClassification(input_channels, seq_len, trial).to(device)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        loss_fn = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "        \n",
    "        train_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.tensor(X_train_fold, dtype=torch.float32),\n",
    "            torch.tensor(y_train_fold, dtype=torch.float32).view(-1, 1),\n",
    "            torch.tensor(w_train_fold, dtype=torch.float32)\n",
    "        )\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "        \n",
    "        model.train()\n",
    "        for ep in range(num_epochs):\n",
    "            for X_batch, y_batch, weight_batch in train_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                weight_batch = weight_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss_per_sample = loss_fn(outputs, y_batch).view(-1)\n",
    "                loss = (loss_per_sample * weight_batch).mean() if use_sample_weights else loss_per_sample.mean()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_val_tensor = torch.tensor(X_val_fold, dtype=torch.float32).to(device)\n",
    "            logits = model(X_val_tensor)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy().reshape(-1)\n",
    "        preds = (probs >= 0.5).astype(np.float32)\n",
    "        overall_acc = np.mean(preds == y_val_fold)\n",
    "        TP = np.sum((preds == 1) & (y_val_fold == 1))\n",
    "        FN = np.sum((preds == 0) & (y_val_fold == 1))\n",
    "        sensitivity = TP / (TP + FN) if (TP + FN) > 0 else np.nan\n",
    "        TN = np.sum((preds == 0) & (y_val_fold == 0))\n",
    "        FP = np.sum((preds == 1) & (y_val_fold == 0))\n",
    "        specificity = TN / (TN + FP) if (TN + FP) > 0 else np.nan\n",
    "        \n",
    "        acc_list.append(overall_acc)\n",
    "        sens_list.append(sensitivity)\n",
    "        spec_list.append(specificity)\n",
    "    \n",
    "    mean_acc = np.mean(acc_list)\n",
    "    mean_sens = np.mean(sens_list)\n",
    "    mean_spec = np.mean(spec_list)\n",
    "    \n",
    "    # For the objective function, we return 1 - mean accuracy (to minimize).\n",
    "    return 1 - mean_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ffb5f19-30b9-4f29-a407-1165f8c97086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_superficial_search_classification(data_dict, use_sample_weights, model_name, n_trials=5):\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    def print_progress(study, trial):\n",
    "        print(f\"{model_name} trial {len(study.trials)}/{n_trials}\\r\", end=\"\", flush=True)\n",
    "    \n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(lambda trial: objective_classification(trial, data_dict, use_sample_weights, model_name),\n",
    "                   n_trials=n_trials, callbacks=[print_progress])\n",
    "    \n",
    "    fig = optuna.visualization.plot_param_importances(study)\n",
    "    plot_filename = f\"search/{model_name}_hyperparam_importance.png\"\n",
    "    fig.write_image(plot_filename)\n",
    "    \n",
    "    rows = []\n",
    "    for t in study.trials:\n",
    "        row = {\"model\": model_name,\n",
    "               \"type\": \"weighted\" if use_sample_weights else \"not weighted\",\n",
    "               \"1 - accuracy\": 1 - t.value,  # since objective is 1-accuracy\n",
    "               \"config\": t.params}\n",
    "        rows.append(row)\n",
    "    result_df = pd.DataFrame(rows)\n",
    "    \n",
    "    best_trial = study.best_trial\n",
    "    optimal_configuration = {\"value\": best_trial.value,\n",
    "                             \"params\": best_trial.params,\n",
    "                             \"user_attrs\": best_trial.user_attrs}\n",
    "    \n",
    "    result_dict = {\"results\": result_df,\n",
    "                   \"optimal_configuration\": optimal_configuration,\n",
    "                   \"importance_plot\": plot_filename}\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb4c2ef-7194-46f4-912f-f4046afa5d92",
   "metadata": {},
   "source": [
    "### Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fda3e0b-6b1c-4cb3-a481-a3bd3edc41b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comb_class_superficial trial 20/20\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'results':                      model      type  1 - accuracy  \\\n",
       " 0   comb_class_superficial  weighted      0.238280   \n",
       " 1   comb_class_superficial  weighted      0.238280   \n",
       " 2   comb_class_superficial  weighted      0.447486   \n",
       " 3   comb_class_superficial  weighted      0.656692   \n",
       " 4   comb_class_superficial  weighted      0.238280   \n",
       " 5   comb_class_superficial  weighted      0.238280   \n",
       " 6   comb_class_superficial  weighted      0.238280   \n",
       " 7   comb_class_superficial  weighted      0.240514   \n",
       " 8   comb_class_superficial  weighted      0.247777   \n",
       " 9   comb_class_superficial  weighted      0.238280   \n",
       " 10  comb_class_superficial  weighted      0.253910   \n",
       " 11  comb_class_superficial  weighted      0.551664   \n",
       " 12  comb_class_superficial  weighted      0.344425   \n",
       " 13  comb_class_superficial  weighted      0.343308   \n",
       " 14  comb_class_superficial  weighted      0.238280   \n",
       " 15  comb_class_superficial  weighted      0.238280   \n",
       " 16  comb_class_superficial  weighted      0.447486   \n",
       " 17  comb_class_superficial  weighted      0.238280   \n",
       " 18  comb_class_superficial  weighted      0.238280   \n",
       " 19  comb_class_superficial  weighted      0.238280   \n",
       " \n",
       "                                                config  \n",
       " 0   {'lr': 0.00038041270512370807, 'use_regulariza...  \n",
       " 1   {'lr': 0.00016363431496194437, 'use_regulariza...  \n",
       " 2   {'lr': 1.5733010822417323e-05, 'use_regulariza...  \n",
       " 3   {'lr': 2.415247870592976e-05, 'use_regularizat...  \n",
       " 4   {'lr': 0.0004271181950646926, 'use_regularizat...  \n",
       " 5   {'lr': 0.0024221895442731716, 'use_regularizat...  \n",
       " 6   {'lr': 0.00016114524266246577, 'use_regulariza...  \n",
       " 7   {'lr': 0.0003000582666581117, 'use_regularizat...  \n",
       " 8   {'lr': 0.0021541424071591063, 'use_regularizat...  \n",
       " 9   {'lr': 0.0006119009553592568, 'use_regularizat...  \n",
       " 10  {'lr': 1.1846515581937759e-05, 'use_regulariza...  \n",
       " 11  {'lr': 1.0863601393523504e-05, 'use_regulariza...  \n",
       " 12  {'lr': 4.2713693918247606e-05, 'use_regulariza...  \n",
       " 13  {'lr': 4.0034190314032976e-05, 'use_regulariza...  \n",
       " 14  {'lr': 3.8321278242986236e-05, 'use_regulariza...  \n",
       " 15  {'lr': 0.008500430100742449, 'use_regularizati...  \n",
       " 16  {'lr': 1.0626733688022218e-05, 'use_regulariza...  \n",
       " 17  {'lr': 9.582499672772863e-05, 'use_regularizat...  \n",
       " 18  {'lr': 2.116862359446997e-05, 'use_regularizat...  \n",
       " 19  {'lr': 7.654112637859866e-05, 'use_regularizat...  ,\n",
       " 'optimal_configuration': {'value': 0.34330776053905165,\n",
       "  'params': {'lr': 2.415247870592976e-05,\n",
       "   'use_regularization': True,\n",
       "   'weight_decay': 6.2487953262754e-06,\n",
       "   'batch_size': 64,\n",
       "   'num_epochs': 5,\n",
       "   'dropout_prob': 0.4502269765949012,\n",
       "   'n_conv': 3,\n",
       "   'n_filters_0': 56,\n",
       "   'kernel_size_0': 5,\n",
       "   'dilation_0': 2,\n",
       "   'stride_0': 2,\n",
       "   'use_pool_0': False,\n",
       "   'n_filters_1': 40,\n",
       "   'kernel_size_1': 5,\n",
       "   'dilation_1': 1,\n",
       "   'stride_1': 1,\n",
       "   'use_pool_1': False,\n",
       "   'n_filters_2': 8,\n",
       "   'kernel_size_2': 5,\n",
       "   'dilation_2': 2,\n",
       "   'stride_2': 2,\n",
       "   'use_pool_2': True,\n",
       "   'pool_type_2': 'avg',\n",
       "   'pool_kernel_2': 2,\n",
       "   'n_hidden': 2,\n",
       "   'n_units_0': 32,\n",
       "   'n_units_1': 48},\n",
       "  'user_attrs': {}},\n",
       " 'importance_plot': 'search/comb_class_superficial_hyperparam_importance.png'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_superficial_search_classification(comb_class_dict, use_sample_weights=True, model_name=\"comb_class_superficial\", n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d57b8d81-8ed7-4efb-8956-734174e64181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitbit_class_superficial trial 20/20\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'results':                        model      type  1 - accuracy  \\\n",
       " 0   fitbit_class_superficial  weighted      0.238280   \n",
       " 1   fitbit_class_superficial  weighted      0.238280   \n",
       " 2   fitbit_class_superficial  weighted      0.238280   \n",
       " 3   fitbit_class_superficial  weighted      0.245524   \n",
       " 4   fitbit_class_superficial  weighted      0.238280   \n",
       " 5   fitbit_class_superficial  weighted      0.238280   \n",
       " 6   fitbit_class_superficial  weighted      0.238280   \n",
       " 7   fitbit_class_superficial  weighted      0.238280   \n",
       " 8   fitbit_class_superficial  weighted      0.248320   \n",
       " 9   fitbit_class_superficial  weighted      0.238280   \n",
       " 10  fitbit_class_superficial  weighted      0.299110   \n",
       " 11  fitbit_class_superficial  weighted      0.332586   \n",
       " 12  fitbit_class_superficial  weighted      0.284045   \n",
       " 13  fitbit_class_superficial  weighted      0.305252   \n",
       " 14  fitbit_class_superficial  weighted      0.238280   \n",
       " 15  fitbit_class_superficial  weighted      0.271734   \n",
       " 16  fitbit_class_superficial  weighted      0.238280   \n",
       " 17  fitbit_class_superficial  weighted      0.238838   \n",
       " 18  fitbit_class_superficial  weighted      0.243856   \n",
       " 19  fitbit_class_superficial  weighted      0.238280   \n",
       " \n",
       "                                                config  \n",
       " 0   {'lr': 0.00010311348468431586, 'use_regulariza...  \n",
       " 1   {'lr': 0.00012026563229698995, 'use_regulariza...  \n",
       " 2   {'lr': 0.0002789869157916967, 'use_regularizat...  \n",
       " 3   {'lr': 0.0030767539826469154, 'use_regularizat...  \n",
       " 4   {'lr': 1.340683601311269e-05, 'use_regularizat...  \n",
       " 5   {'lr': 5.808014512440447e-05, 'use_regularizat...  \n",
       " 6   {'lr': 0.0023408677856086094, 'use_regularizat...  \n",
       " 7   {'lr': 2.6720665582131664e-05, 'use_regulariza...  \n",
       " 8   {'lr': 9.97785885301262e-05, 'use_regularizati...  \n",
       " 9   {'lr': 0.0014189100054141704, 'use_regularizat...  \n",
       " 10  {'lr': 0.009612170696245148, 'use_regularizati...  \n",
       " 11  {'lr': 0.008996368265343476, 'use_regularizati...  \n",
       " 12  {'lr': 0.009653720006801115, 'use_regularizati...  \n",
       " 13  {'lr': 0.0099877621192885, 'use_regularization...  \n",
       " 14  {'lr': 0.0008151274615737027, 'use_regularizat...  \n",
       " 15  {'lr': 0.00471598331452379, 'use_regularizatio...  \n",
       " 16  {'lr': 0.0006247242558423687, 'use_regularizat...  \n",
       " 17  {'lr': 0.00501810745461877, 'use_regularizatio...  \n",
       " 18  {'lr': 0.0016627657615352134, 'use_regularizat...  \n",
       " 19  {'lr': 0.0003012428778863315, 'use_regularizat...  ,\n",
       " 'optimal_configuration': {'value': 0.6674141392135199,\n",
       "  'params': {'lr': 0.008996368265343476,\n",
       "   'use_regularization': True,\n",
       "   'weight_decay': 1.2509940946776174e-06,\n",
       "   'batch_size': 48,\n",
       "   'num_epochs': 7,\n",
       "   'dropout_prob': 0.24288675187761766,\n",
       "   'n_conv': 1,\n",
       "   'n_filters_0': 64,\n",
       "   'kernel_size_0': 5,\n",
       "   'dilation_0': 2,\n",
       "   'stride_0': 1,\n",
       "   'use_pool_0': True,\n",
       "   'pool_type_0': 'avg',\n",
       "   'pool_kernel_0': 2,\n",
       "   'n_hidden': 0},\n",
       "  'user_attrs': {}},\n",
       " 'importance_plot': 'search/fitbit_class_superficial_hyperparam_importance.png'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_superficial_search_classification(fitbit_class_dict, use_sample_weights=True, model_name=\"fitbit_class_superficial\", n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d45d0a-12ed-4ee5-bccd-22e8245adf90",
   "metadata": {},
   "source": [
    "### Not Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82dd9017-39a8-42f9-b03e-c73d772c9f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comb_class_superficial_nw trial 20/20\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'results':                         model          type  1 - accuracy  \\\n",
       " 0   comb_class_superficial_nw  not weighted      0.762830   \n",
       " 1   comb_class_superficial_nw  not weighted      0.761720   \n",
       " 2   comb_class_superficial_nw  not weighted      0.761162   \n",
       " 3   comb_class_superficial_nw  not weighted      0.761720   \n",
       " 4   comb_class_superficial_nw  not weighted      0.448893   \n",
       " 5   comb_class_superficial_nw  not weighted      0.342458   \n",
       " 6   comb_class_superficial_nw  not weighted      0.732147   \n",
       " 7   comb_class_superficial_nw  not weighted      0.701436   \n",
       " 8   comb_class_superficial_nw  not weighted      0.761720   \n",
       " 9   comb_class_superficial_nw  not weighted      0.736044   \n",
       " 10  comb_class_superficial_nw  not weighted      0.761720   \n",
       " 11  comb_class_superficial_nw  not weighted      0.760612   \n",
       " 12  comb_class_superficial_nw  not weighted      0.737184   \n",
       " 13  comb_class_superficial_nw  not weighted      0.761720   \n",
       " 14  comb_class_superficial_nw  not weighted      0.761720   \n",
       " 15  comb_class_superficial_nw  not weighted      0.751672   \n",
       " 16  comb_class_superficial_nw  not weighted      0.761720   \n",
       " 17  comb_class_superficial_nw  not weighted      0.757813   \n",
       " 18  comb_class_superficial_nw  not weighted      0.748328   \n",
       " 19  comb_class_superficial_nw  not weighted      0.762277   \n",
       " \n",
       "                                                config  \n",
       " 0   {'lr': 0.004485143245341955, 'use_regularizati...  \n",
       " 1   {'lr': 0.00022106696871100672, 'use_regulariza...  \n",
       " 2   {'lr': 1.028191126031416e-05, 'use_regularizat...  \n",
       " 3   {'lr': 6.774791976247743e-05, 'use_regularizat...  \n",
       " 4   {'lr': 1.1860274257600749e-05, 'use_regulariza...  \n",
       " 5   {'lr': 2.1193928331383803e-05, 'use_regulariza...  \n",
       " 6   {'lr': 0.003094511369208091, 'use_regularizati...  \n",
       " 7   {'lr': 0.0021570065127881665, 'use_regularizat...  \n",
       " 8   {'lr': 0.0001066188879386928, 'use_regularizat...  \n",
       " 9   {'lr': 0.00035152090711017075, 'use_regulariza...  \n",
       " 10  {'lr': 0.00917183031208695, 'use_regularizatio...  \n",
       " 11  {'lr': 0.0006278102823611427, 'use_regularizat...  \n",
       " 12  {'lr': 0.0011337485420324753, 'use_regularizat...  \n",
       " 13  {'lr': 0.00014169429199994537, 'use_regulariza...  \n",
       " 14  {'lr': 0.009880565062450325, 'use_regularizati...  \n",
       " 15  {'lr': 0.00025973718979973177, 'use_regulariza...  \n",
       " 16  {'lr': 4.420050126055986e-05, 'use_regularizat...  \n",
       " 17  {'lr': 0.003681588966895999, 'use_regularizati...  \n",
       " 18  {'lr': 0.0011063084506372051, 'use_regularizat...  \n",
       " 19  {'lr': 0.00028641575037658204, 'use_regulariza...  ,\n",
       " 'optimal_configuration': {'value': 0.23717028991145483,\n",
       "  'params': {'lr': 0.004485143245341955,\n",
       "   'use_regularization': True,\n",
       "   'weight_decay': 9.31754536725629e-05,\n",
       "   'batch_size': 16,\n",
       "   'num_epochs': 5,\n",
       "   'dropout_prob': 0.12785061377363977,\n",
       "   'n_conv': 1,\n",
       "   'n_filters_0': 32,\n",
       "   'kernel_size_0': 3,\n",
       "   'dilation_0': 1,\n",
       "   'stride_0': 1,\n",
       "   'use_pool_0': True,\n",
       "   'pool_type_0': 'max',\n",
       "   'pool_kernel_0': 4,\n",
       "   'n_hidden': 2,\n",
       "   'n_units_0': 80,\n",
       "   'n_units_1': 48},\n",
       "  'user_attrs': {}},\n",
       " 'importance_plot': 'search/comb_class_superficial_nw_hyperparam_importance.png'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_superficial_search_classification(comb_class_dict, use_sample_weights=False, model_name=\"comb_class_superficial_nw\", n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de2fb548-ac59-46fd-85ef-deefa7c9c1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitbit_class_superficial_nw trial 20/20\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'results':                           model          type  1 - accuracy  \\\n",
       " 0   fitbit_class_superficial_nw  not weighted      0.761720   \n",
       " 1   fitbit_class_superficial_nw  not weighted      0.741633   \n",
       " 2   fitbit_class_superficial_nw  not weighted      0.762279   \n",
       " 3   fitbit_class_superficial_nw  not weighted      0.761720   \n",
       " 4   fitbit_class_superficial_nw  not weighted      0.761720   \n",
       " 5   fitbit_class_superficial_nw  not weighted      0.761720   \n",
       " 6   fitbit_class_superficial_nw  not weighted      0.761720   \n",
       " 7   fitbit_class_superficial_nw  not weighted      0.761720   \n",
       " 8   fitbit_class_superficial_nw  not weighted      0.740496   \n",
       " 9   fitbit_class_superficial_nw  not weighted      0.760046   \n",
       " 10  fitbit_class_superficial_nw  not weighted      0.761720   \n",
       " 11  fitbit_class_superficial_nw  not weighted      0.748873   \n",
       " 12  fitbit_class_superficial_nw  not weighted      0.598084   \n",
       " 13  fitbit_class_superficial_nw  not weighted      0.761720   \n",
       " 14  fitbit_class_superficial_nw  not weighted      0.761720   \n",
       " 15  fitbit_class_superficial_nw  not weighted      0.761720   \n",
       " 16  fitbit_class_superficial_nw  not weighted      0.761720   \n",
       " 17  fitbit_class_superficial_nw  not weighted      0.761720   \n",
       " 18  fitbit_class_superficial_nw  not weighted      0.756137   \n",
       " 19  fitbit_class_superficial_nw  not weighted      0.761720   \n",
       " \n",
       "                                                config  \n",
       " 0   {'lr': 3.991040332634252e-05, 'use_regularizat...  \n",
       " 1   {'lr': 0.0011106741730643657, 'use_regularizat...  \n",
       " 2   {'lr': 0.00032471615872753173, 'use_regulariza...  \n",
       " 3   {'lr': 4.311062330624422e-05, 'use_regularizat...  \n",
       " 4   {'lr': 0.0001312386806814069, 'use_regularizat...  \n",
       " 5   {'lr': 5.966118181704454e-05, 'use_regularizat...  \n",
       " 6   {'lr': 0.0001674359098200047, 'use_regularizat...  \n",
       " 7   {'lr': 0.002246005562303994, 'use_regularizati...  \n",
       " 8   {'lr': 0.0073485013343507445, 'use_regularizat...  \n",
       " 9   {'lr': 0.002243974242638831, 'use_regularizati...  \n",
       " 10  {'lr': 0.00047822765284716653, 'use_regulariza...  \n",
       " 11  {'lr': 1.0162565719775751e-05, 'use_regulariza...  \n",
       " 12  {'lr': 1.057715203555096e-05, 'use_regularizat...  \n",
       " 13  {'lr': 4.610468484537456e-05, 'use_regularizat...  \n",
       " 14  {'lr': 0.00039145485926028045, 'use_regulariza...  \n",
       " 15  {'lr': 0.00010530601924948202, 'use_regulariza...  \n",
       " 16  {'lr': 3.256010999801717e-05, 'use_regularizat...  \n",
       " 17  {'lr': 0.0008020164393067116, 'use_regularizat...  \n",
       " 18  {'lr': 2.0634902628775938e-05, 'use_regulariza...  \n",
       " 19  {'lr': 0.0002444032625259308, 'use_regularizat...  ,\n",
       " 'optimal_configuration': {'value': 0.23772116836028068,\n",
       "  'params': {'lr': 0.00032471615872753173,\n",
       "   'use_regularization': True,\n",
       "   'weight_decay': 6.147209686087819e-06,\n",
       "   'batch_size': 64,\n",
       "   'num_epochs': 9,\n",
       "   'dropout_prob': 0.333983801990087,\n",
       "   'n_conv': 1,\n",
       "   'n_filters_0': 40,\n",
       "   'kernel_size_0': 7,\n",
       "   'dilation_0': 1,\n",
       "   'stride_0': 2,\n",
       "   'use_pool_0': False,\n",
       "   'n_hidden': 0},\n",
       "  'user_attrs': {}},\n",
       " 'importance_plot': 'search/fitbit_class_superficial_nw_hyperparam_importance.png'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_superficial_search_classification(fitbit_class_dict, use_sample_weights=False, model_name=\"fitbit_class_superficial_nw\", n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b1cc05-d910-43f0-a1d2-54d8f172ffb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL_py_env)",
   "language": "python",
   "name": "dl_py_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
